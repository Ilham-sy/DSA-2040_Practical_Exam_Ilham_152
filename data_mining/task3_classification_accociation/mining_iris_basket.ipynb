{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240183b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree Classifier ===\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "=== KNN Classifier (k=5) ===\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "KNN performed better.\n",
      "\n",
      "=== Association Rule Mining ===\n",
      "\n",
      "Sample Transactions:\n",
      "     item1  item2   item3    item4    item5 item6 item7 item8\n",
      "0  butter   beer    eggs     None     None  None  None  None\n",
      "1    milk  juice  carrot   butter  diapers  None  None  None\n",
      "2  tomato   rice  cheese     None     None  None  None  None\n",
      "3  coffee   rice  yogurt     None     None  None  None  None\n",
      "4     tea  pasta  yogurt  diapers     None  None  None  None\n",
      "\n",
      "Top 5 Rules by Lift:\n",
      "   antecedent consequent  support  confidence      lift\n",
      "0  (butter,)  (carrot,)      0.2    0.666667  2.222222\n",
      "1  (carrot,)  (butter,)      0.2    0.666667  2.222222\n",
      "2    (rice,)  (yogurt,)      0.2    0.666667  2.000000\n",
      "3  (yogurt,)    (rice,)      0.2    0.600000  2.000000\n",
      "\n",
      "Analysis of Rule: If a customer buys ['butter'], they are likely to also buy ['carrot'] with a confidence of 0.67 and lift 2.22.\n"
     ]
    }
   ],
   "source": [
    "# mining_iris_basket.py\n",
    "# Task 3: Classification and Association Rule Mining (No mlxtend install needed)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "# ================================\n",
    "# Load Preprocessed Iris Data\n",
    "# ================================\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\Ayan\\Documents\\DSA 2040_Practical_Exam_Ilham_152\\data_mining\\task1_preprocessing\\iris_preprocessed.csv\"\n",
    ")\n",
    "X = df.drop(columns=['species'])\n",
    "y = df['species']  # Keep original target labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# Part A: Classification\n",
    "# ================================\n",
    "print(\"\\n=== Decision Tree Classifier ===\")\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt, average='weighted'))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_dt, average='weighted'))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt, feature_names=X.columns, class_names=y.unique(), filled=True)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.savefig(\"decision_tree.png\")\n",
    "plt.close()\n",
    "\n",
    "# KNN Classifier\n",
    "print(\"\\n=== KNN Classifier (k=5) ===\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_knn, average='weighted'))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_knn, average='weighted'))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Model comparison\n",
    "if accuracy_score(y_test, y_pred_dt) > accuracy_score(y_test, y_pred_knn):\n",
    "    print(\"Decision Tree performed better.\")\n",
    "else:\n",
    "    print(\"KNN performed better.\")\n",
    "\n",
    "# ================================\n",
    "# Part B: Association Rule Mining (Pure pandas, no mlxtend)\n",
    "# ================================\n",
    "print(\"\\n=== Association Rule Mining ===\")\n",
    "\n",
    "# Generate synthetic basket data\n",
    "items_pool = [\n",
    "    'milk', 'bread', 'beer', 'diapers', 'eggs', 'butter', 'cheese', 'apple', 'banana', 'chicken',\n",
    "    'rice', 'pasta', 'tomato', 'onion', 'carrot', 'yogurt', 'juice', 'coffee', 'tea', 'sugar'\n",
    "]\n",
    "transactions = [random.sample(items_pool, random.randint(3, 8)) for _ in range(30)]\n",
    "df_basket = pd.DataFrame(transactions, columns=[f'item{i}' for i in range(1, 9)])\n",
    "print(\"\\nSample Transactions:\\n\", df_basket.head())\n",
    "\n",
    "# One-hot encoding\n",
    "all_items = sorted(set(item for basket in transactions for item in basket))\n",
    "onehot_df = pd.DataFrame(0, index=range(len(transactions)), columns=all_items)\n",
    "for i, basket in enumerate(transactions):\n",
    "    for item in basket:\n",
    "        onehot_df.loc[i, item] = 1\n",
    "\n",
    "# Function to compute support\n",
    "def support(itemset):\n",
    "    return onehot_df[list(itemset)].all(axis=1).mean()\n",
    "\n",
    "# Generate frequent itemsets\n",
    "frequent_itemsets = []\n",
    "min_support = 0.2\n",
    "for length in range(1, 4):\n",
    "    for combo in combinations(all_items, length):\n",
    "        s = support(combo)\n",
    "        if s >= min_support:\n",
    "            frequent_itemsets.append((combo, s))\n",
    "\n",
    "frequent_itemsets_df = pd.DataFrame(frequent_itemsets, columns=[\"itemset\", \"support\"])\n",
    "\n",
    "# Generate rules\n",
    "rules_list = []\n",
    "min_confidence = 0.5\n",
    "for itemset, supp in frequent_itemsets:\n",
    "    if len(itemset) >= 2:\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in combinations(itemset, i):\n",
    "                consequent = tuple(set(itemset) - set(antecedent))\n",
    "                conf = support(itemset) / support(antecedent)\n",
    "                lift = conf / support(consequent)\n",
    "                if conf >= min_confidence:\n",
    "                    rules_list.append((antecedent, consequent, supp, conf, lift))\n",
    "\n",
    "rules_df = pd.DataFrame(rules_list, columns=[\"antecedent\", \"consequent\", \"support\", \"confidence\", \"lift\"])\n",
    "rules_df = rules_df.sort_values(by=\"lift\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Rules by Lift:\\n\", rules_df.head())\n",
    "\n",
    "# Rule analysis example\n",
    "if not rules_df.empty:\n",
    "    example_rule = rules_df.iloc[0]\n",
    "    print(f\"\\nAnalysis of Rule: If a customer buys {list(example_rule['antecedent'])}, \"\n",
    "          f\"they are likely to also buy {list(example_rule['consequent'])} \"\n",
    "          f\"with a confidence of {example_rule['confidence']:.2f} and lift {example_rule['lift']:.2f}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
